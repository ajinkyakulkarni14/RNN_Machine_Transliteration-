{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import codecs\n",
      "import collections\n",
      "#NETCDF_HELPERS............................ \n",
      "from Scientific.IO.NetCDF import NetCDFFile\n",
      "from numpy import *\n",
      "from scipy import *\n",
      "from optparse import OptionParser\n",
      "import sys\n",
      "import os\n",
      "import subprocess\n",
      "import glob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class netcdf:\n",
      "    def __init__(self,):\n",
      "        pass\n",
      "    def createNcDim(self,ncfile,name,d):\n",
      "        #print \"creating netcdf dimension:\",name,d\n",
      "        ncfile.createDimension(name,d)\n",
      "    \n",
      "    def createNcVar(self,ncfile,vname,data,vtype,dims,desc):\n",
      "        #print \"creating netcdf variable\",vname\n",
      "        nc_var = ncfile.createVariable (vname,vtype,dims)\n",
      "        nc_var.longname\t= desc\n",
      "        nc_var.assignValue(data)\n",
      "        #print shape(nc_var)\n",
      "    \n",
      "    def maxLen(self,strings):\n",
      "        maxLength=0\n",
      "        for s in strings:\n",
      "            length=len(s)\n",
      "            if (length>maxLength):\n",
      "                maxLength=length\n",
      "        return maxLength\n",
      "\n",
      "    def createNcStrings(self,ncfile,vname,strings,dims,desc):\n",
      "        #print \"wrting strings\", vname\n",
      "        maxLength = self.maxLen(strings) + 1\n",
      "        nullStrings = []\n",
      "        for s in strings:\n",
      "            nullStrings.append(list(s) +['\\0']*(maxLength - len(s)))\n",
      "        self.createNcDim(ncfile,dims[1],maxLength)\n",
      "        self.createNcVar(ncfile,vname,array(nullStrings),'c',dims,desc)\n",
      "        \n",
      "    def create_temp_nc(self,input_string,labels,dict_map,nc_path,delayed_number):\n",
      "        temp_path=nc_path\n",
      "        seqDims = []\n",
      "        seqLengths = []\n",
      "        targetStrings = []#list of ground truth with space sperated characters and space in gnd replaced with *\n",
      "        wordTargetStrings = []#list of ground truth with space replaced with * !!\n",
      "        seqTags = []\n",
      "        inputs = []\n",
      "        seqTags.append(str(1))\n",
      "        word=\"-\"\n",
      "        wts=word.encode('unicode_escape')\n",
      "        #print wts\n",
      "        wordTargetStrings.append(wts)\n",
      "        ts = \"\"\n",
      "        for c in word:\n",
      "            label = c.encode('unicode_escape')\n",
      "            ts += label + ' '\n",
      "        ts = ts.strip()\n",
      "        targetStrings.append(ts)\n",
      "        oldlen = len(inputs)\n",
      "        for k in input_string:\n",
      "            if dict_map.get(k)!=None:\n",
      "                id_val=float(dict_map[k])\n",
      "            else:\n",
      "                id_val=0.0\n",
      "            inputs.append([id_val,0.0])\n",
      "            inputs.append([float(delayed_number),float(delayed_number)])\n",
      "        #inputs[-1][-1] = 1#penup pendown indicator !!\n",
      "        #print inputs\n",
      "        seqLengths.append(len(inputs) - oldlen)\n",
      "        seqDims.append([seqLengths[-1]])\n",
      "        #skip the normalisation term !!\n",
      "        #create a new .nc file\n",
      "        file = NetCDFFile(temp_path, 'w')\n",
      "\n",
      "        #create the dimensions\n",
      "        self.createNcDim(file,'numSeqs',len(seqLengths))#no of lines !!\n",
      "        self.createNcDim(file,'numTimesteps',len(inputs))# featlen*noofInstnces*noOfSamples!!\n",
      "        self.createNcDim(file,'inputPattSize',len(inputs[0]))#feature len !!\n",
      "        self.createNcDim(file,'numDims',1) #?\n",
      "        self.createNcDim(file,'numLabels',len(labels))# no of uniq labels\n",
      "\n",
      "        #create the variables\n",
      "        self.createNcStrings(file,'seqTags',seqTags,('numSeqs','maxSeqTagLength'),'sequence tags')#list of samplename files !!\n",
      "        self.createNcStrings(file,'labels',labels,('numLabels','maxLabelLength'),'labels')#labels uniq list\n",
      "        self.createNcStrings(file,'targetStrings',targetStrings,('numSeqs','maxTargStringLength'),'target strings')#targetstrings\n",
      "        self.createNcStrings(file,'wordTargetStrings',wordTargetStrings,('numSeqs','maxWordTargStringLength'),'word target strings')#wordstraings\n",
      "        self.createNcVar(file,'seqLengths',seqLengths,'i',('numSeqs',),'sequence lengths')#list of seqlengths[l,l,l]\n",
      "        self.createNcVar(file,'seqDims',seqDims,'i',('numSeqs','numDims'),'sequence dimensions')#seqDims [[l],[l],[l]]\n",
      "        self.createNcVar(file,'inputs',inputs,'f',('numTimesteps','inputPattSize'),'input patterns')#inputs !!\n",
      "\n",
      "        #write the data to disk\n",
      "        #print \"closing file\", temp_path\n",
      "        file.close()    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class preprocess:\n",
      "    def __init__(self,dict_map_path,labels_path,weight_path,nc_path,delayed_number):\n",
      "        self.dict_map_path=dict_map_path\n",
      "        self.labels_path=labels_path\n",
      "        self.weight_path=weight_path\n",
      "        self.dict_map={}\n",
      "        self.labels=[]\n",
      "        self.delayed_number=delayed_number\n",
      "    def init_preprocess(self,):\n",
      "        fp=codecs.open(self.dict_map_path,'r')\n",
      "        for f in fp:\n",
      "            self.dict_map[f.split(':')[0].strip()]=int(f.split(':')[1].strip())\n",
      "        fp.close()\n",
      "        fp=codecs.open(self.labels_path,'r')\n",
      "        for f in fp:\n",
      "            self.labels.append(str(f.strip()))\n",
      "        fp.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class postprocess:\n",
      "    def __init__(self,weight_path,nc_path,dir_path):\n",
      "        self.weight_path=weight_path\n",
      "        self.nc_path=nc_path\n",
      "        self.dir_path=dir_path\n",
      "    def run_rnn(self,):\n",
      "        cmd1=\"rnnlib --trainFile='\"\"' --valFile='\"\"' --testFile=%s --dataset=test --verbose=true --errorTest=true %s\"%(nc_path,weight_path)\n",
      "        f=subprocess.Popen(cmd1,shell=True)\n",
      "    def parse_log(self,):\n",
      "        #print glob.glob(\"%s*.log\"%(dir_path))[0]\n",
      "        del_path=glob.glob(\"%s*.log\"%(dir_path))\n",
      "        if del_path==[]:\n",
      "            return 'No LOG FILE FOUND'\n",
      "        else:\n",
      "            fpr=codecs.open(del_path[0],\"r\")\n",
      "            output=' '\n",
      "            for f in fpr:\n",
      "                #print f.strip()\n",
      "                if f.find('output label sequence')!=-1:\n",
      "                    #print fpr.next().strip()\n",
      "                    for i in fpr.next().strip().split():\n",
      "                        output=output+unichr(int(i[2:], 16))\n",
      "            \n",
      "            os.remove(del_path[0])\n",
      "            #os.remove(self.nc_path)\n",
      "            return output.strip()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class main:\n",
      "    def __init__(self,path_dictmap,weight_path,nc_path,dir_path,labels_path,delayed_number):\n",
      "        self._netcdf=netcdf()\n",
      "        self._preprocess=preprocess(path_dictmap,labels_path,weight_path,nc_path,delayed_number)\n",
      "        self._postprocess=postprocess(weight_path,nc_path,dir_path)\n",
      "        self._preprocess.init_preprocess()\n",
      "    def marathi_transliterate(self,input_string):\n",
      "        labels=self._preprocess.labels\n",
      "        dict_map=self._preprocess.dict_map\n",
      "        nc_path=self._postprocess.nc_path\n",
      "        delayed_number=self._preprocess.delayed_number\n",
      "        self._netcdf.create_temp_nc(input_string,labels,dict_map,nc_path,delayed_number)\n",
      "        self._postprocess.run_rnn()\n",
      "        print self._postprocess.parse_log()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path_dictmap='/home/ajinkyak/Workspace/Research_Work/HIN_transliteration_demo/Transliteration_data_creation/dict_map.txt'\n",
      "weight_path='/home/ajinkyak/Workspace/Research_Work/HIN_transliteration_demo/Transliteration_data_creation/transcription@2016.02.23-18.04.43.525906.best_labelError.save'\n",
      "nc_path='/home/ajinkyak/Workspace/Research_Work/HIN_transliteration_demo/Transliteration_data_creation/temp_mr.nc'\n",
      "dir_path='/home/ajinkyak/Workspace/Research_Work/HIN_transliteration_demo/Transliteration_data_creation/'\n",
      "labels_path='/home/ajinkyak/Workspace/Research_Work/HIN_transliteration_demo/Transliteration_data_creation/labels.txt'\n",
      "delayed_number=28"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mar_transliterate=main(path_dictmap,weight_path,nc_path,dir_path,labels_path,delayed_number)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mar_transliterate.marathi_transliterate('ona')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u0913\u0928\u093e\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}